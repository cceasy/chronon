package build.cloud_gcp
import mill.api._
import mill.scalalib.*

import java.util.jar.JarFile

// Cloud GCP module - supports both cloud_gcp.test AND cloud_gcp[2.13.17].test
object `package` extends Cross[CloudGcpModule](build.Constants.scalaVersions) with CloudGcpModule {
  // Provide default scala version for bracket-free access
  override val crossValue = build.Constants.defaultScalaVersion
}

trait CloudGcpModule extends Cross.Module[String] with build.BaseModule {
  def moduleDeps = Seq(build.spark(crossValue), build.aggregator(crossValue), build.api(crossValue), build.online(crossValue))
  def bigqueryJarFile = Task.Source(moduleDir / "iceberg-bigquery-1.11.0-SNAPSHOT.jar")
  
  def excludeJackson(dep: mill.scalalib.Dep): mill.scalalib.Dep = {
    dep
      .exclude("com.fasterxml.jackson.core" -> "jackson-core")
      .exclude("com.fasterxml.jackson.core" -> "jackson-databind")
      .exclude("com.fasterxml.jackson.core" -> "jackson-annotations")
      .exclude("com.fasterxml.jackson.datatype" -> "jackson-datatype-jsr310")    
  }

  // Merge strategy for assembly
  // Needed to avoid conflicts with Dataproc serverless
//  override def assemblyRules = super.assemblyRules ++ Seq(
//    Assembly.Rule.Relocate("org.apache.iceberg.gcp.bigquery.**", "shade.org.apache.iceberg.gcp.bigquery.@1")
//  )
  override def unmanagedClasspath = Task {
    super.unmanagedClasspath() ++ Seq(bigqueryJarFile())
  }

  def compileMvnDeps = build.Constants.sparkDeps ++ Seq(
    mvn"com.google.cloud.spark:spark-3.5-bigquery:0.42.0",
  )

//  val googleBigdataVersion = "2.2.26"
  def mvnDeps = build.Constants.commonDeps ++
    build.Constants.loggingApiDeps ++
    build.Constants.utilityDeps ++
    Seq(
      mvn"com.google.cloud:google-cloud-storage:2.49.0",
      mvn"com.google.cloud:google-cloud-dataproc:4.52.0",
      mvn"com.google.cloud:google-cloud-pubsub:1.134.2",
      mvn"com.google.cloud.hosted.kafka:managed-kafka-auth-login-handler:1.0.6",
      mvn"org.apache.iceberg::iceberg-spark-runtime-3.5:1.10.0",
      mvn"com.google.cloud:google-cloud-bigquery:2.54.1",
      mvn"com.google.cloud:google-cloud-bigtable:2.57.1",
      mvn"io.vertx:vertx-web-client:4.5.22",
      mvn"com.google.auth:google-auth-library-oauth2-http:1.40.0",
  ).map(excludeJackson) ++ Seq(
    mvn"com.fasterxml.jackson.core:jackson-core:2.15.2",
    mvn"com.fasterxml.jackson.core:jackson-databind:2.15.2",
    mvn"com.fasterxml.jackson.core:jackson-annotations:2.15.2",
    mvn"com.fasterxml.jackson.module::jackson-module-scala:2.15.2",
    mvn"com.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.15.2",
  ).map(_.forceVersion())
  
  object test extends build.BaseTestModule {
    def scalaVersion = crossValue

    def moduleDeps = Seq(build.cloud_gcp(crossValue), build.spark(crossValue).test)
    override def testFramework = "org.scalatest.tools.Framework"
    def forkArgs = build.Constants.commonTestForkArgs ++ Seq(
      "-Dspark.sql.adaptive.enabled=false",
      "-Dspark.sql.adaptive.coalescePartitions.enabled=false",
      "-Dspark.serializer=org.apache.spark.serializer.KryoSerializer",
      "-Dspark.sql.hive.convertMetastoreParquet=false"
    )

    def compileMvnDeps = build.Constants.sparkDeps ++ Seq(
      mvn"org.apache.iceberg:iceberg-bigquery:1.10.0",
    )

    override def mvnDeps = super.mvnDeps() ++ build.Constants.sparkDeps ++ build.Constants.testDeps ++ Seq(
      excludeJackson(mvn"com.google.cloud.spark:spark-3.5-bigquery:0.42.0"),
      // Use exact versions from Bazel configuration
      excludeJackson(mvn"com.google.cloud:google-cloud-bigtable-emulator:0.178.0")
        .exclude("io.grpc" -> "grpc-core")
        .exclude("io.grpc" -> "grpc-stub")
        .exclude("io.grpc" -> "grpc-inprocess")
        .exclude("com.google.api" -> "gax")
        .exclude("com.google.api" -> "gax-grpc"),
    )
  }
}